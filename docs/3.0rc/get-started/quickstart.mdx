---
title: Quickstart
description: Get started with Prefect, the easiest way to orchestrate and observe your data pipelines
---

Prefect is an orchestration and observability platform that empowers developers to build and scale code quickly, turning Python scripts into resilient, recurring workflows.
Take a Python script to a production-ready, remotely executable workflow in minutes.

In this quickstart, you'll schedule your code on remote infrastructure and observe the state of your workflows.

## Example

In this quickstart, you will use Prefect to convert the following Python script to a schedulable, observable, resilient, and deployable workflow.

```python
import httpx

def get_repo_info():
    """Fetch statistics about https://github.com/PrefectHQ/prefect"""
    url = "https://api.github.com/repos/PrefectHQ/prefect"
    response = httpx.get(url)
    repo = response.json()
    print("PrefectHQ/prefect repository statistics ðŸ¤“:")
    print(f"Stars ðŸŒ  : {repo['stargazers_count']}")

if __name__ == "__main__":
    get_repo_info()
```

## Install Prefect

Install the Prefect client.
If needed, see [Install Prefect](/3.0rc/get-started/install/) for other options.

```bash
pip install -U prefect==3.0.0rc2"
```

## Connect to Prefect's API

Connect to the Prefect API with Cloud or OSS:

<Tabs>
  <Tab title="Cloud">
1. Head to [https://app.prefect.cloud/](https://app.prefect.cloud/) and sign in or create a forever-free Prefect Cloud account.
1. Use the `prefect cloud login` CLI command to log in to Prefect Cloud from your development environment.

```bash
prefect cloud login
```

Choose **Log in with a web browser** and click the **Authorize** button in the browser window that opens.
Your CLI is now authenticated with your Prefect Cloud account through a locally-stored API key that expires in 30 days.

If you have any issues with browser-based authentication, see the [Prefect Cloud docs](/3.0rc/cloud/manage-users/api-keys/) to learn how to authenticate with a manually created API key.
  </Tab>
  <Tab title="OSS">
Spin up a local Prefect server:

```bash
prefect server start
```
  </Tab>
</Tabs>

## Convert your script to a Prefect flow

The easiest way convert a Python script into a workflow is to add a `@flow` decorator.
[Flows](/3.0rc/develop/write-flows/) are the core observable, deployable units in Prefect and are the primary entrypoint to orchestrated work.

The following flow calls two tasks, each defined by the `@task` decorator.
Tasks are the smallest unit of observed and orchestrated work in Prefect.

```python my_gh_workflow.py
import httpx   # an HTTP client library and dependency of Prefect
from prefect import flow, task

@task(retries=2)
def get_repo_info(repo_owner: str, repo_name: str):
    """Get info about a repo - will retry twice after failing"""
    url = f"https://api.github.com/repos/{repo_owner}/{repo_name}"
    api_response = httpx.get(url)
    api_response.raise_for_status()
    repo_info = api_response.json()
    return repo_info

@task
def get_contributors(repo_info: dict):
    """Get contributors for a repo"""
    contributors_url = repo_info["contributors_url"]
    response = httpx.get(contributors_url)
    response.raise_for_status()
    contributors = response.json()
    return contributors

@flow(log_prints=True)
def repo_info(repo_owner: str = "PrefectHQ", repo_name: str = "prefect"):
    """
    Given a GitHub repository, logs the number of stargazers
    and contributors for that repo.
    """
    repo_info = get_repo_info(repo_owner, repo_name)
    print(f"Stars ðŸŒ  : {repo_info['stargazers_count']}")

    contributors = get_contributors(repo_info)
    print(f"Number of contributors ðŸ‘·: {len(contributors)}")

if __name__ == "__main__":
    repo_info()
```

<Note>
The `log_prints=True` argument provided to the `@flow` decorator logs output from `print` statements within the function.
</Note>

## Run your flow

Run your Prefect flow.

```bash
python my_gh_workflow.py
```

Prefect automatically tracks the state of the flow run and logs the output in the UI and CLI.

```bash
14:28:31.099 | INFO    | prefect.engine - Created flow run 'energetic-panther' for flow 'repo-info'
14:28:31.100 | INFO    | Flow run 'energetic-panther' - View at https://app.prefect.cloud/account/123/workspace/abc/flow-runs/flow-run/xyz
14:28:32.178 | INFO    | Flow run 'energetic-panther' - Created task run 'get_repo_info-0' for task 'get_repo_info'
14:28:32.179 | INFO    | Flow run 'energetic-panther' - Executing 'get_repo_info-0' immediately...
14:28:32.584 | INFO    | Task run 'get_repo_info-0' - Finished in state Completed()
14:28:32.599 | INFO    | Flow run 'energetic-panther' - Stars ðŸŒ  : 13609
14:28:32.682 | INFO    | Flow run 'energetic-panther' - Created task run 'get_contributors-0' for task 'get_contributors'
14:28:32.682 | INFO    | Flow run 'energetic-panther' - Executing 'get_contributors-0' immediately...
14:28:33.118 | INFO    | Task run 'get_contributors-0' - Finished in state Completed()
14:28:33.134 | INFO    | Flow run 'energetic-panther' - Number of contributors ðŸ‘·: 30
14:28:33.255 | INFO    | Flow run 'energetic-panther' - Finished in state Completed('All states completed.')
```

## Create a work pool

Running a flow locally is a good start, but you should use a remote destination for production flows.
Create a work pool with Cloud or OSS.

<Tabs>
  <Tab title="Cloud">
Create a [managed work pool](/3.0rc/deploy/serve-flows/index):

```bash
prefect work-pool create my-work-pool --type prefect:managed
```

You can view your new work pool on the **Work Pools** page of the UI.
  </Tab>
  <Tab title="OSS">
In this example, we'll create a Docker type work pool, but you can choose from other [work pool types](https://docs.prefect.io/concepts/work-pools/#worker-types).

<Info>
You need to have Docker installed and running on your machine to create a Docker work pool.
</Info>

Create a Docker type work pool:

```bash
prefect work-pool create --type docker my-work-pool
```

Verify that the work pool exists:

```bash
prefect work-pool ls
```
  </Tab>
</Tabs>

## Deploy and schedule your flow

A [deployment](/3.0rc/deploy/serve-flows/) schedules a flow function to run in your work pool.
Deployments elevate flows to remotely configurable entities that have their own API.

This next script builds a deployment, identifying:

- Source for the code to deploy (here, a GitHub repo)
- Specific flow to run (`my_gh_workflow.py:repo_info`)
- Work pool target (`my-work-pool`)
- Cron schedule (1am every day)

```bash create_deployment.py
from prefect import flow

# The repository to query
SOURCE_REPO="https://github.com/prefecthq/demos.git"

if __name__ == "__main__":
    flow.from_source(
        source=SOURCE_REPO,
        entrypoint="my_gh_workflow.py:repo_info",
    ).deploy(
        name="my-first-deployment",
        work_pool_name="my-work-pool",
        cron="0 1 * * *",
    )
```

<Tip>
You can store your flow code in nearly any location as long as Prefect can access it.
See [Where to store your flow code](/3.0rc/deploy/dynamic-infra/retrieve-flow-code) for more details.
</Tip>

Run the script to create the deployment.

<Tabs>
  <Tab title="Cloud">
```bash
python create_deployment.py
```
  </Tab>
  <Tab title="OSS">
```bash
TBD
```
  </Tab>
</Tabs>

You see a message that your deployment was created:

```bash
Successfully created/updated all deployments!
______________________________________________________
|                    Deployments                     |  
______________________________________________________
|    Name                       |  Status  | Details |
______________________________________________________
| repo-info/my-first-deployment | applied  |         |
______________________________________________________
```

To schedule a run for the deployment:

<Tabs>
  <Tab title="Cloud">
You can run your flow with the Prefect UI on the **Deployments** page.

The deployment is configured to run on a Prefect Managed work pool, so Prefect automatically spins up the infrastructure to run the flow. 

After a minute or so, you should see the flow run graph and logs on the Flow Run page in the UI.

![Managed flow run graph and logs](/3.0rc/img/ui/qs-flow-run.png)

<Warning>
    After testing this process, click the **Remove** button in the top right of the **Deployment** page so that the workflow is no longer scheduled to run once per day.
</Warning>
  </Tab>
  <Tab title="OSS">
```bash
prefect deployment run 'repo-info/my-first-deployment'
```
  </Tab>
</Tabs>

## Next steps

You've seen how to move from a Python script to a scheduled, observable, remotely orchestrated workflow with Prefect.
Now considering reading: 

* [Write flows](/3.0rc/develop/write-flows/index)
* [Write tasks](/3.0rc/develop/write-tasks/index)
* [Self-host](/3.0rc/cloud/self-host) your Prefect server

<Tip>
[Book a meeting](https://calendly.com/prefect-experts/prefect-product-advocates?utm_campaign=prefect_docs_cloud&utm_content=prefect_docs&utm_medium=docs&utm_source=docs) with a Prefect Product Advocate to get your questions answered.
</Tip>
